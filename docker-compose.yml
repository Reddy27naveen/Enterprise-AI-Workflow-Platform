services:
  postgres:
    image: postgres:18.1-alpine
    container_name: postgres
    environment:
      POSTGRES_USER: ${POSTGRES_USER}
      POSTGRES_PASSWORD: ${POSTGRES_PASSWORD}
      POSTGRES_DB: ${POSTGRES_DB}
    volumes:
      - postgres_data:/var/lib/postgresql/data
      - ./scripts/init-databases.sh:/docker-entrypoint-initdb.d/init-databases.sh
    ports:
      - "5432:5432"
    networks:
      - ai_network
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U ${POSTGRES_USER}"]
      interval: 10s
      timeout: 5s
      retries: 5
    restart: unless-stopped

  redis:
    image: redis:8.4-alpine
    container_name: redis
    command: redis-server --requirepass ${REDIS_PASSWORD} --maxmemory 2gb --maxmemory-policy allkeys-lru
    volumes:
      - redis_data:/data
    ports:
      - "6379:6379"
    networks:
      - ai_network
    healthcheck:
      test: ["CMD", "redis-cli", "-a", "${REDIS_PASSWORD}", "ping"]
      interval: 10s
      timeout: 5s
      retries: 5
    restart: unless-stopped

  minio:
    image: minio/minio:latest
    container_name: minio
    command: server /data --console-address ":9001"
    environment:
      MINIO_ROOT_USER: ${MINIO_ROOT_USER}
      MINIO_ROOT_PASSWORD: ${MINIO_ROOT_PASSWORD}
    volumes:
      - minio_data:/data
    ports:
      - "9000:9000"
      - "9001:9001"
    networks:
      - ai_network
    restart: unless-stopped

  weaviate:
    image: semitechnologies/weaviate:1.34.8
    container_name: weaviate
    environment:
      AUTHENTICATION_ANONYMOUS_ACCESS_ENABLED: 'true'
      PERSISTENCE_DATA_PATH: '/var/lib/weaviate'
      DEFAULT_VECTORIZER_MODULE: 'none'
      ENABLE_MODULES: 'text2vec-openai,generative-openai'
    volumes:
      - weaviate_data:/var/lib/weaviate
    ports:
      - "8081:8080"
    networks:
      - ai_network
    restart: unless-stopped

  mlflow:
    build: ./services/mlflow
    container_name: mlflow
    environment:
      MLFLOW_S3_ENDPOINT_URL: http://minio:9000
      AWS_ACCESS_KEY_ID: ${MINIO_ROOT_USER}
      AWS_SECRET_ACCESS_KEY: ${MINIO_ROOT_PASSWORD}
    command: mlflow server --backend-store-uri postgresql://${POSTGRES_USER}:${POSTGRES_PASSWORD}@postgres:5432/mlflow --default-artifact-root s3://mlflow-artifacts/ --host 0.0.0.0 --port 5000
    ports:
      - "5000:5000"
    depends_on:
      postgres:
        condition: service_healthy
      minio:
        condition: service_started
    networks:
      - ai_network
    restart: unless-stopped

  airflow-init:
    image: my-custom-airflow:latest
    build: ./services/airflow 
    container_name: airflow-init
    environment: &airflow-env
      AIRFLOW__CORE__EXECUTOR: LocalExecutor
      AIRFLOW__DATABASE__SQL_ALCHEMY_CONN: postgresql+psycopg2://${POSTGRES_USER}:${POSTGRES_PASSWORD}@postgres:5432/airflow
      AIRFLOW__CORE__FERNET_KEY: ${AIRFLOW_FERNET_KEY}
      AIRFLOW__WEBSERVER__SECRET_KEY: ${AIRFLOW_SECRET_KEY}
      AIRFLOW__API__SECRET_KEY: ${AIRFLOW_SECRET_KEY}
      AIRFLOW__CORE__LOAD_EXAMPLES: 'false'
      AIRFLOW__WEBSERVER__EXPOSE_CONFIG: 'true'
      AIRFLOW__CORE__DAGS_ARE_PAUSED_AT_CREATION: 'false'
      AIRFLOW__CORE__AUTH_MANAGER: airflow.providers.fab.auth_manager.fab_auth_manager.FabAuthManager
      AIRFLOW__SCHEDULER__ENABLE_HEALTH_CHECK: 'true'
      AIRFLOW__CORE__EXECUTION_API_SERVER_URL: 'http://airflow-api-server:8080/execution/'
      _AIRFLOW_DB_MIGRATE: 'true'
      _AIRFLOW_WWW_USER_CREATE: 'true'
      _AIRFLOW_WWW_USER_USERNAME: admin
      _AIRFLOW_WWW_USER_PASSWORD: admin
      _AIRFLOW_WWW_USER_FIRSTNAME: Admin
      _AIRFLOW_WWW_USER_LASTNAME: User
      _AIRFLOW_WWW_USER_EMAIL: admin@example.com
      _AIRFLOW_WWW_USER_ROLE: Admin
      OPENAI_API_KEY: ${OPENAI_API_KEY}
      ANTHROPIC_API_KEY: ${ANTHROPIC_API_KEY}
      GOOGLE_API_KEY: ${GOOGLE_API_KEY}
      AWS_ACCESS_KEY_ID: ${AWS_ACCESS_KEY_ID}
      AWS_SECRET_ACCESS_KEY: ${AWS_SECRET_ACCESS_KEY}
      AWS_REGION: ${AWS_REGION:-us-east-1}
    user: "0:0"
    volumes:
      - ./services/airflow/dags:/opt/airflow/dags
      - ./services/airflow/logs:/opt/airflow/logs
      - ./services/airflow/plugins:/opt/airflow/plugins
    command: >
      bash -c "airflow db migrate && true"
    depends_on:
      postgres:
        condition: service_healthy
    networks:
      - ai_network
    restart: "no"
  airflow-api-server:
    image: my-custom-airflow:latest
    container_name: airflow-api-server
    environment: *airflow-env
    user: "${AIRFLOW_UID}:0"
    command: api-server
    ports:
      - "8080:8080"
    volumes:
      - ./services/airflow/dags:/opt/airflow/dags
      - ./services/airflow/logs:/opt/airflow/logs
      - ./services/airflow/plugins:/opt/airflow/plugins
    depends_on:
      airflow-init:
        condition: service_completed_successfully
    networks:
      - ai_network
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "curl", "--fail", "http://localhost:8080/api/v2/version"]
      interval: 30s
      timeout: 10s
      retries: 5
      start_period: 80s

  airflow-scheduler:
    image: my-custom-airflow:latest
    container_name: airflow-scheduler
    environment: *airflow-env
    user: "${AIRFLOW_UID}:0"
    command: scheduler
    volumes:
      - ./services/airflow/dags:/opt/airflow/dags
      - ./services/airflow/logs:/opt/airflow/logs
      - ./services/airflow/plugins:/opt/airflow/plugins
    depends_on:
      airflow-init:
        condition: service_completed_successfully
    networks:
      - ai_network
    restart: unless-stopped

  airflow-triggerer:
    image: my-custom-airflow:latest
    container_name: airflow-triggerer
    environment: *airflow-env
    user: "${AIRFLOW_UID}:0"
    command: triggerer
    volumes:
      - ./services/airflow/dags:/opt/airflow/dags
      - ./services/airflow/logs:/opt/airflow/logs
      - ./services/airflow/plugins:/opt/airflow/plugins
    depends_on:
      airflow-init:
        condition: service_completed_successfully
    networks:
      - ai_network
    restart: unless-stopped

  api:
    build: ./services/api
    container_name: fastapi-api
    environment:
      OPENAI_API_KEY: ${OPENAI_API_KEY}
      ANTHROPIC_API_KEY: ${ANTHROPIC_API_KEY}
      GOOGLE_API_KEY: ${GOOGLE_API_KEY}
      AWS_ACCESS_KEY_ID: ${AWS_ACCESS_KEY_ID}
      AWS_SECRET_ACCESS_KEY: ${AWS_SECRET_ACCESS_KEY}
      AWS_REGION: ${AWS_REGION:-us-east-1}
      POSTGRES_URL: postgresql://${POSTGRES_USER}:${POSTGRES_PASSWORD}@postgres:5432/app
      REDIS_URL: redis://:${REDIS_PASSWORD}@redis:6379/0
      WEAVIATE_URL: http://weaviate:8080
      MLFLOW_TRACKING_URI: http://mlflow:5000
    ports:
      - "8000:8000"
    volumes:
      - ./services/api:/app
    depends_on:
      postgres:
        condition: service_healthy
      redis:
        condition: service_healthy
      weaviate:
        condition: service_started
    networks:
      - ai_network
    restart: unless-stopped

  gradio:
    build: ./services/gradio
    container_name: gradio-ui
    environment:
      API_URL: http://api:8000
    ports:
      - "7860:7860"
    depends_on:
      - api
    networks:
      - ai_network
    restart: unless-stopped

  prometheus:
    image: prom/prometheus:latest
    container_name: prometheus
    command:
      - '--config.file=/etc/prometheus/prometheus.yml'
      - '--storage.tsdb.path=/prometheus'
    volumes:
      - ./config/prometheus.yml:/etc/prometheus/prometheus.yml
      - prometheus_data:/prometheus
    ports:
      - "9090:9090"
    networks:
      - ai_network
    restart: unless-stopped

  grafana:
    image: grafana/grafana:latest
    container_name: grafana
    environment:
      GF_SECURITY_ADMIN_USER: admin
      GF_SECURITY_ADMIN_PASSWORD: admin
    volumes:
      - grafana_data:/var/lib/grafana
      - ./config/grafana:/etc/grafana/provisioning
    ports:
      - "3000:3000"
    depends_on:
      - prometheus
    networks:
      - ai_network
    restart: unless-stopped

networks:
  ai_network:
    driver: bridge

volumes:
  postgres_data:
  redis_data:
  minio_data:
  weaviate_data:
  prometheus_data:
  grafana_data: